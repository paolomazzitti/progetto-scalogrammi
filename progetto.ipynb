{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download msambare/fer2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Specify the path to the zip file\n",
    "zip_file_path = 'fer2013.zip'\n",
    "\n",
    "# Specify the path to the destination folder\n",
    "destination_folder = 'dataset'\n",
    "\n",
    "# Check if the destination folder exists, create it if it doesn't\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolomazzitti/anaconda3/envs/laurea/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/paolomazzitti/anaconda3/envs/laurea/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /Users/paolomazzitti/anaconda3/envs/laurea/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <AD0702F8-F0F4-3872-8C19-A834018634B4> /Users/paolomazzitti/anaconda3/envs/laurea/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(128, ratio=(0.95, 1.05)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create the dataset \n",
    "dataset_train = dataset.ImageFolder(root='dataset/train', transform=transform)\n",
    "dataset_test = dataset.ImageFolder(root='dataset/test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 3995, 'disgust': 436, 'fear': 4097, 'happy': 7215, 'neutral': 4965, 'sad': 4830, 'surprise': 3171}\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'dataset/train'\n",
    "num_images_per_class = {cls: len(os.listdir(os.path.join(train_dir, cls))) for cls in dataset_train.classes}\n",
    "print(num_images_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class_counts = torch.tensor([num_images_per_class[cls] for cls in dataset_train.classes], dtype=torch.float)\n",
    "class_weights = 1. / class_counts\n",
    "weights = torch.tensor([class_weights[cls] for _, cls in dataset_train.samples])\n",
    "sampler = WeightedRandomSampler(weights, len(weights)) # type: ignore\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, sampler=sampler)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 3., 3., 5., 1., 3.])\n",
      "tensor([3., 1., 3., 3., 3., 1., 2.])\n",
      "tensor([2., 0., 3., 2., 0., 6., 3.])\n",
      "tensor([2., 3., 4., 0., 2., 4., 1.])\n",
      "tensor([2., 0., 5., 1., 3., 2., 3.])\n",
      "tensor(1.5628)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from itertools import islice\n",
    "\n",
    "var_counts = []\n",
    "for i, (X_batch, y_batch) in enumerate(islice(train_loader, 5)):\n",
    "    bin_count = torch.bincount(y_batch).type(torch.float)\n",
    "    var_counts.append(torch.std(bin_count))\n",
    "    print(bin_count)\n",
    "var_counts_tensor = torch.tensor(var_counts)\n",
    "print(torch.mean(var_counts_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28709"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.normal_(m.weight, mean=0, std=0.05)\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.normal_(m.weight, mean=0, std=0.05)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size=2, stride=2, padding='valid'),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size=3, padding='same', dilation=2),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.identity = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=2, stride=2, padding='valid'),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.sequential(x)\n",
    "        x2 = self.identity(x)\n",
    "        res = x1 + x2\n",
    "        res = torch.nn.functional.relu(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.normal_(m.weight, mean=0, std=0.05)\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.normal_(m.weight, mean=0, std=0.05)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(output_channels, input_channels, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size=3, padding='same', dilation=2),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.sequential(x)\n",
    "        res = x1 + x\n",
    "        res = torch.nn.functional.relu(res)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemon(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stage_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.stage_2 = nn.Sequential(\n",
    "            ResBlock(32, 48, 0.3),\n",
    "            IdentityBlock(32, 48, 0.2)\n",
    "        )\n",
    "\n",
    "        self.stage_3 = nn.Sequential(\n",
    "            ResBlock(48, 64, 0.2),\n",
    "            IdentityBlock(48, 64, 0.2)\n",
    "        )\n",
    "\n",
    "        self.stage_4 = nn.Sequential(\n",
    "            ResBlock(64, 80, 0.1),\n",
    "            IdentityBlock(64, 80, 0.1)\n",
    "        )\n",
    "\n",
    "        self.stage_5 = nn.Sequential(\n",
    "            ResBlock(80, 96, 0.1),\n",
    "            IdentityBlock(80, 96, 0.1)\n",
    "        )\n",
    "\n",
    "        self.stage_6 = nn.Sequential(\n",
    "            ResBlock(96, 112, 0.0),\n",
    "            IdentityBlock(96, 112, 0.0)\n",
    "        )\n",
    "\n",
    "        self.stage_7 = nn.Sequential(\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(112, 144),\n",
    "            nn.Linear(144, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage_1(x)\n",
    "        x = self.stage_2(x)\n",
    "        x = self.stage_3(x)\n",
    "        x = self.stage_4(x)\n",
    "        x = self.stage_5(x)\n",
    "        x = self.stage_6(x)\n",
    "        x = self.stage_7(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    net = nn.Sequential(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(112, 144),\n",
    "            nn.Linear(144, 7)\n",
    "        ))\n",
    "    return net\n",
    "\n",
    "model = get_net()\n",
    "model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Epoch 0 --\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0629ba92df1f418485e2c0ededc5da06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m     29\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(predictions, y_batch)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/laurea/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/laurea/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "model = Lemon()\n",
    "model = torch.jit.script(model)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "state_dict = {}\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Addestramento\n",
    "for epoch in range(100):\n",
    "    state_dict['epoch'] = epoch\n",
    "    train_loss = torch.Tensor()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_samples = 0\n",
    "    print(f\" -- Epoch {epoch} --\")\n",
    "    for X_batch, y_batch in tqdm(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        train_loss = loss_fn(predictions, y_batch)\n",
    "        train_loss.backward()\n",
    "        total_train_loss += train_loss.item() * X_batch.size(0)\n",
    "        total_samples += X_batch.size(0)\n",
    "        optimizer.step()\n",
    "    average_train_loss = total_train_loss / total_samples\n",
    "    train_losses.append(average_train_loss)\n",
    "    print(f\"Train loss: {average_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = 0\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    test_losses = []\n",
    "    total_test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            total_test_loss += loss.item() * X_batch.size(0)\n",
    "            total_samples += X_batch.size(0)\n",
    "        average_test_loss = total_test_loss / total_samples\n",
    "        test_losses.append(average_test_loss)\n",
    "        print(f\"Test loss: {average_test_loss}\")\n",
    "\n",
    "    state_dict['model_state_dict'] = model.state_dict()\n",
    "    state_dict['optimizer_state_dict'] = optimizer.state_dict()\n",
    "    state_dict['train_losses'] = train_losses\n",
    "    state_dict['test_losses'] = test_losses\n",
    "    torch.save(state_dict, \"lemon.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Lemon                                    [32, 7]                   --\n",
       "├─Sequential: 1-1                        [32, 32, 64, 64]          --\n",
       "│    └─Conv2d: 2-1                       [32, 32, 128, 128]        896\n",
       "│    └─BatchNorm2d: 2-2                  [32, 32, 128, 128]        64\n",
       "│    └─ELU: 2-3                          [32, 32, 128, 128]        --\n",
       "│    └─MaxPool2d: 2-4                    [32, 32, 64, 64]          --\n",
       "│    └─Dropout: 2-5                      [32, 32, 64, 64]          --\n",
       "├─Sequential: 1-2                        [32, 48, 32, 32]          --\n",
       "│    └─ResBlock: 2-6                     [32, 48, 32, 32]          --\n",
       "│    │    └─Sequential: 3-1              [32, 48, 32, 32]          36,784\n",
       "│    │    └─Sequential: 3-2              [32, 48, 32, 32]          6,288\n",
       "│    └─IdentityBlock: 2-7                [32, 48, 32, 32]          --\n",
       "│    │    └─Sequential: 3-3              [32, 48, 32, 32]          46,512\n",
       "├─Sequential: 1-3                        [32, 64, 16, 16]          --\n",
       "│    └─ResBlock: 2-8                     [32, 64, 16, 16]          --\n",
       "│    │    └─Sequential: 3-4              [32, 64, 16, 16]          78,960\n",
       "│    │    └─Sequential: 3-5              [32, 64, 16, 16]          12,480\n",
       "│    └─IdentityBlock: 2-9                [32, 64, 16, 16]          --\n",
       "│    │    └─Sequential: 3-6              [32, 64, 16, 16]          97,392\n",
       "├─Sequential: 1-4                        [32, 80, 8, 8]            --\n",
       "│    └─ResBlock: 2-10                    [32, 80, 8, 8]            --\n",
       "│    │    └─Sequential: 3-7              [32, 80, 8, 8]            137,008\n",
       "│    │    └─Sequential: 3-8              [32, 80, 8, 8]            20,720\n",
       "│    └─IdentityBlock: 2-11               [32, 80, 8, 8]            --\n",
       "│    │    └─Sequential: 3-9              [32, 80, 8, 8]            166,704\n",
       "├─Sequential: 1-5                        [32, 96, 4, 4]            --\n",
       "│    └─ResBlock: 2-12                    [32, 96, 4, 4]            --\n",
       "│    │    └─Sequential: 3-10             [32, 96, 4, 4]            210,928\n",
       "│    │    └─Sequential: 3-11             [32, 96, 4, 4]            31,008\n",
       "│    └─IdentityBlock: 2-13               [32, 96, 4, 4]            --\n",
       "│    │    └─Sequential: 3-12             [32, 96, 4, 4]            254,448\n",
       "├─Sequential: 1-6                        [32, 112, 2, 2]           --\n",
       "│    └─ResBlock: 2-14                    [32, 112, 2, 2]           --\n",
       "│    │    └─Sequential: 3-13             [32, 112, 2, 2]           300,720\n",
       "│    │    └─Sequential: 3-14             [32, 112, 2, 2]           43,344\n",
       "│    └─IdentityBlock: 2-15               [32, 112, 2, 2]           --\n",
       "│    │    └─Sequential: 3-15             [32, 112, 2, 2]           360,624\n",
       "├─Sequential: 1-7                        [32, 7]                   --\n",
       "│    └─AvgPool2d: 2-16                   [32, 112, 1, 1]           --\n",
       "│    └─Flatten: 2-17                     [32, 112]                 --\n",
       "│    └─Linear: 2-18                      [32, 144]                 16,272\n",
       "│    └─Linear: 2-19                      [32, 7]                   1,015\n",
       "==========================================================================================\n",
       "Total params: 1,822,167\n",
       "Trainable params: 1,822,167\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.93\n",
       "==========================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 536.16\n",
       "Params size (MB): 7.29\n",
       "Estimated Total Size (MB): 549.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(Lemon(), input_size=(32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flax'"
     ]
    }
   ],
   "source": [
    "import flax\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
